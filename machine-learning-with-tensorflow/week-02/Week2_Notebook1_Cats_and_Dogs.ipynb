{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIBl4fxjCL-M"
      },
      "source": [
        "# Image Preprocessing and Binary Classification with Keras\n",
        "\n",
        "## Objective\n",
        "In this week's exercise, you will:\n",
        "1. Learn how to image preprocessing in keras.\n",
        "2. Build and train a multilayer neural network for binary classification on a real-world dataset of cats and dogs.\n",
        "\n",
        "---\n",
        "\n",
        "## Step 1: Import Libraries\n",
        "Let's start by importing the necessary libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "keXtDJE8CL-N"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONC17Xo6CL-O"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 2: Load and Preprocess the Data\n",
        "We will use the Keras `ImageDataGenerator` for image augmentation and preprocessing.\n",
        "First, unzip the uploaded dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AEqeufzCL-P"
      },
      "outputs": [],
      "source": [
        "!unzip -q cats_and_dogs.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install opendatasets\n",
        "!pip install opendatasets --quiet\n",
        "\n",
        "# Import the library\n",
        "import opendatasets as od\n",
        "\n",
        "# Download the Cats and Dogs dataset from Kaggle\n",
        "# Replace `kaggle-url` with the actual Kaggle URL for the dataset\n",
        "od.download(\"https://www.kaggle.com/c/dogs-vs-cats/data\")"
      ],
      "metadata": {
        "id": "KhPR9FlPCNfP",
        "outputId": "6029bcdd-b63f-467d-da15-b340f6841d9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username:"
          ]
        },
        {
          "output_type": "error",
          "ename": "Abort",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAbort\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-9b4096c3af13>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Download the Cats and Dogs dataset from Kaggle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Replace `kaggle-url` with the actual Kaggle URL for the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://www.kaggle.com/c/dogs-vs-cats/data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/opendatasets/__init__.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(dataset_id_or_url, data_dir, force, dry_run, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Check for a Kaggle dataset URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_kaggle_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdownload_kaggle_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_id_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdry_run\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdry_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Check for Google Drive URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/opendatasets/utils/kaggle_api.py\u001b[0m in \u001b[0;36mdownload_kaggle_dataset\u001b[0;34m(dataset_url, data_dir, force, dry_run)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mread_kaggle_creds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'KAGGLE_USERNAME'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Your Kaggle username\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'KAGGLE_KEY'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_kaggle_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/click/termui.py\u001b[0m in \u001b[0;36mprompt\u001b[0;34m(text, default, hide_input, confirmation_prompt, type, value_proc, prompt_suffix, show_default, err, show_choices)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/click/termui.py\u001b[0m in \u001b[0;36mprompt_func\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhide_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mecho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAbort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalue_proc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAbort\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaedYeTBCL-P"
      },
      "source": [
        "## Step 3: Learn about undersampling and implement it\n",
        "Research online what undersampling and random undersampling is. It is a very powerful technique used often in machine Learning. Find out when it is used and undersample your dataset using \"random undersampling\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qugjs-liCL-P"
      },
      "outputs": [],
      "source": [
        "# undersample your dataset here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyMsKIA0CL-Q"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 4: Set Up ImageDataGenerator (or well more specifically the new version)\n",
        "Were Sorry - the videos from the coursera course are sometimes not the most up to date. In this case the 'ImageDataGenerator' function is deprecated (look here https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) and will be removed in the future versions. The concept behind the new reccomended function is very similar though.\n",
        "The new reccomendation is loading images with tf.keras.utils.image_dataset_from_directory and transforming the output tf.data.Dataset with preprocessing layers.\n",
        "\n",
        "You may use Chat GPT for this task and you can also check the following tutorials <br>\n",
        "https://www.tensorflow.org/tutorials/load_data/images <br>\n",
        "https://www.tensorflow.org/tutorials/load_data/images <br>\n",
        "https://www.tensorflow.org/guide/keras/preprocessing_layers <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxkBez18CL-R"
      },
      "outputs": [],
      "source": [
        "# TODO create a dataset using the recommended methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoUltXA7CL-R"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 5: Build a Multilayer Neural Network\n",
        "Now, let's build a multilayer neural network for binary classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pF4B1oK7CL-S"
      },
      "outputs": [],
      "source": [
        "# TODO build a model\n",
        "\n",
        "# TODO compile the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtKpzYiuCL-S"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 6: Train the Model\n",
        "Train the model using the Dataset you created\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L03-951eCL-T"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxTtJ2phCL-T"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 7: Evaluate the Model\n",
        "After training, you may upload some test images to evaluate your model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RjvjEVCCL-U"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "def load_and_predict(model):\n",
        "    uploaded_files = files.upload()\n",
        "\n",
        "    for fn in uploaded_files.keys():\n",
        "        path = '/content/' + fn\n",
        "        img = image.load_img(path, target_size=(150, 150))\n",
        "\n",
        "        x = image.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0) / 255.0\n",
        "\n",
        "        classes = model.predict(x)\n",
        "        result = \"a dog\" if classes[0] > 0.5 else \"a cat\"\n",
        "\n",
        "        print(f'The model predicts that the image is of {result}')\n",
        "\n",
        "# Call the function to upload images and get predictions\n",
        "load_and_predict(model)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".ve_tensorflow_course",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}